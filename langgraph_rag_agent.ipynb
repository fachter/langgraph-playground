{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:43:56.047325Z",
     "start_time": "2024-05-08T11:43:56.036227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ],
   "id": "92ed04723a3ef5db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:43:56.050516Z",
     "start_time": "2024-05-08T11:43:56.048553Z"
    }
   },
   "source": "local_llm = \"llama3\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:43:59.701659Z",
     "start_time": "2024-05-08T11:43:56.051374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "id": "e4c131088aa5ea52",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieval Grader",
   "id": "53ecb22b7a69a243"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:03.146070Z",
     "start_time": "2024-05-08T11:43:59.702815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "demo_question = \"agent memory\"\n",
    "docs = retriever.invoke(demo_question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": demo_question, \"document\": doc_txt}))"
   ],
   "id": "36bbc99a51ded321",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate",
   "id": "546db2f5845ee585"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:10.074738Z",
     "start_time": "2024-05-08T11:44:03.148403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(documents):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "demo_question = \"agent memory\"\n",
    "docs = retriever.invoke(demo_question)\n",
    "generated_answer = rag_chain.invoke({\"context\": docs, \"question\": demo_question})\n",
    "print(generated_answer)"
   ],
   "id": "87506377cb57b0c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, agent memory refers to a long-term memory module (external database) that records a comprehensive list of agents' experience in natural language. This memory stream enables agents to behave conditioned on past experience and interact with other agents.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hallucination Grader",
   "id": "75d8e6060fcf127f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:16.818127Z",
     "start_time": "2024-05-08T11:44:10.076732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"documents\", \"generation\"]\n",
    ")\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"generation\": generated_answer, \"documents\": docs})"
   ],
   "id": "3ae77a035e77887d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Answer Grader",
   "id": "13faf17b58e43b91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:17.923254Z",
     "start_time": "2024-05-08T11:44:16.819598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"generation\"]\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"generation\": generated_answer, \"question\": demo_question})"
   ],
   "id": "2b31a4e960b181d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Router",
   "id": "131f51a7fd8583b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.214814Z",
     "start_time": "2024-05-08T11:44:17.924346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on LLM agents, \n",
    "    prompt engineering, and adversarial attacks. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question_router.invoke({\"question\": demo_question})"
   ],
   "id": "9ed7aa7929af829e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasource': 'vectorstore'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.233430Z",
     "start_time": "2024-05-08T11:44:19.215790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ],
   "id": "f232f65a8d3284a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.236748Z",
     "start_time": "2024-05-08T11:44:19.234350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict, NotRequired\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: NotRequired[str]\n",
    "    web_search: NotRequired[str]\n",
    "    documents: List[str]"
   ],
   "id": "4e3304ac91c1091c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.241788Z",
     "start_time": "2024-05-08T11:44:19.237473Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.schema import Document",
   "id": "abb722dc1ea1aa11",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Nodes",
   "id": "f666d69a677e62f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.247971Z",
     "start_time": "2024-05-08T11:44:19.242560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve(state: GraphState) -> GraphState:\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state.get(\"question\")\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state: GraphState) -> GraphState:\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state.get(\"question\")\n",
    "    documents = state.get(\"documents\")\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    print(\"---GRADE_DOCS---\")\n",
    "    question = state.get(\"question\")\n",
    "    documents = state.get(\"documents\")\n",
    "\n",
    "    filtered_docs = []\n",
    "    should_perform_web_search = \"No\"\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": doc.page_content}\n",
    "        )\n",
    "        grade = score.get(\"score\")\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            should_perform_web_search = \"Yes\"\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": should_perform_web_search}\n",
    "\n",
    "\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    print(\"---WEB_SEARCH---\")\n",
    "    question = state.get(\"question\")\n",
    "    documents = state.get(\"documents\")\n",
    "\n",
    "    web_docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in web_docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}\n"
   ],
   "id": "7503928dfe76f920",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Conditional Edges",
   "id": "67304d67b038dab4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.253205Z",
     "start_time": "2024-05-08T11:44:19.248812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def route_question(state: GraphState) -> str:\n",
    "    print(\"---ROUTE_QUESTION---\")\n",
    "    question = state.get(\"question\")\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.get(\"datasource\") == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    should_perform_web_search = state.get(\"web_search\")\n",
    "\n",
    "    if should_perform_web_search == \"Yes\":\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state: GraphState) -> str:\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state.get(\"question\")\n",
    "    documents = state.get(\"documents\")\n",
    "    generation = state.get(\"generation\")\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score.get(\"score\")\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.get(\"score\")\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n"
   ],
   "id": "1e47c81051a6650e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.257931Z",
     "start_time": "2024-05-08T11:44:19.256052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Node:\n",
    "    websearch = \"websearch\"\n",
    "    retrieve = \"retrieve\"\n",
    "    generate = \"generate\"\n",
    "    grade_documents = \"grade_documents\"\n",
    "    "
   ],
   "id": "ac4e5a9fcceb2f54",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graph Build",
   "id": "24cb407c82646a86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.280814Z",
     "start_time": "2024-05-08T11:44:19.258774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(Node.websearch, web_search)\n",
    "workflow.add_node(Node.retrieve, retrieve)\n",
    "workflow.add_node(Node.grade_documents, grade_documents)\n",
    "workflow.add_node(Node.generate, generate)"
   ],
   "id": "dc92f7a9dc0438dc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:19.284766Z",
     "start_time": "2024-05-08T11:44:19.281909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": Node.websearch,\n",
    "        \"vectorstore\": Node.retrieve\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(Node.retrieve, Node.grade_documents)\n",
    "workflow.add_conditional_edges(\n",
    "    Node.grade_documents,\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": Node.websearch,\n",
    "        \"generate\": Node.generate\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(Node.websearch, Node.generate)\n",
    "workflow.add_conditional_edges(\n",
    "    Node.generate,\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": Node.generate,\n",
    "        \"useful\": END,\n",
    "        \"not useful\": Node.websearch\n",
    "    }\n",
    ")"
   ],
   "id": "46b0ec2bee6320b4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:44:41.698775Z",
     "start_time": "2024-05-08T11:44:19.285688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app = workflow.compile()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "last_value = None\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "        last_value = value\n",
    "pprint(last_value[\"generation\"])"
   ],
   "id": "5899a3dc2bb223a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE_QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---GRADE_DOCS---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---DECISION: GENERATE---\n",
      "'Finished running: grade_documents:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "'Finished running: generate:'\n",
      "('According to the provided context, there are two types of agent memory '\n",
      " 'mentioned:\\n'\n",
      " '\\n'\n",
      " '1. Memory stream: a long-term memory module that records a comprehensive '\n",
      " \"list of agents' experience in natural language.\\n\"\n",
      " '2. Reflection mechanism: synthesizes memories into higher-level inferences '\n",
      " \"over time and guides the agent's future behavior.\\n\"\n",
      " '\\n'\n",
      " 'These types of memory enable the agent to behave conditioned on past '\n",
      " 'experience, as well as interact with other agents.')\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:45:48.518106Z",
     "start_time": "2024-05-08T11:45:36.187248Z"
    }
   },
   "cell_type": "code",
   "source": "app.invoke({\"question\": \"What is zero-shot learning?\"})",
   "id": "e4da42ec4a140ae1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE_QUESTION---\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "---WEB_SEARCH---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is zero-shot learning?',\n",
       " 'generation': \"Zero-shot learning is a machine learning scenario where an AI model is trained to recognize and categorize objects or concepts without having seen any examples of those categories or concepts beforehand. This setup uses auxiliary information, such as textual descriptions, during the training process instead of explicit labels. The goal is to recognize things that the model hasn't explicitly seen before in training.\",\n",
       " 'documents': [Document(page_content='Zero-shot Learning is a setup in which a model can learn to recognize things that it hasn\\'t explicitly seen before in training. There are different zero-shot learning approaches, but a commonality is that auxiliary information such as textual descriptions are used or encoded during the training process instead of explicit labels.\\nZero-shot classification refers to the problem setting where we want to recognize objects from classes that our model has not seen during training. In zero shot learning the data consists of. Unseen classes: These are classes for which labelled images are not present during the training phase.\\nZero-shot learning (ZSL) is a machine learning scenario in which an AI model is trained to recognize and categorize objects or concepts without having seen any examples of those categories or concepts beforehand. Most state-of-the-art deep learning models for classification or regression are trained through supervised learning, which requires ...\\nZero Shot Classification is the task of predicting a class that wasn\\'t seen by the model during training. This method, which leverages a pre-trained language model, can be thought of as an instance of transfer learning which generally refers to using a model trained for one task in a different application than what it was originally trained for ...\\nThis problem is widely studied in computer vision, natural language processing, and machine perception.[2]\\nBackground and history[edit]\\nThe first paper on zero-shot learning in natural language processing appeared in 2008 at the AAAI’08, but the name given to the learning paradigm there was dataless classification.[3] The first paper on zero-shot learning in computer vision appeared at the same conference, under the name zero-data learning.[4] Moreover, beyond relying solely on representations, the computational approach has been extended to depend on transfer from other tasks, such as textual entailment[11] and question answering.[12]\\nThe original paper[3] also points out that, beyond the ability to classify a single example, when a collection of examples is given, with the assumption that they come from the same distribution, it is possible to bootstrap the performance in a semi-supervised like manner (or transductive learning).\\n This terminology was repeated later in another computer vision paper[6] and the term zero-shot learning caught on, as a take-off on one-shot learning that was introduced in computer vision years earlier.[7]\\nIn computer vision, zero-shot learning models learned parameters for seen classes along with their class representations and rely on representational similarity among class labels so that, during inference, instances can be classified into new classes.\\n Contents\\nZero-shot learning\\nZero-shot learning (ZSL) is a problem setup in deep learning where, at test time, a learner observes samples from classes which were not observed during training, and needs to predict the class that they belong to. In natural language processing, the key technical direction developed builds on the ability to \"understand the labels\"—represent the labels in the same semantic space as that of the documents to be classified.')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:48:19.168674Z",
     "start_time": "2024-05-08T11:47:55.781250Z"
    }
   },
   "cell_type": "code",
   "source": "app.invoke({\"question\": \"What is zero-shot learning in the context of prompt engineering?\"})",
   "id": "57e8f255b33ee55f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE_QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "---GRADE_DOCS---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "---WEB_SEARCH---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is zero-shot learning in the context of prompt engineering?',\n",
       " 'generation': 'In the context of prompt engineering, zero-shot learning refers to a method where the model is asked to perform a task without any additional examples or guidance. The model relies solely on its pre-trained information to generate an output.',\n",
       " 'web_search': 'Yes',\n",
       " 'documents': [Document(page_content='Zero-shot generation: This is to find a number of prompts that can trigger harmful output conditioned on a preset prompt.\\nStochastic few-shot generation: The red team prompts found from the above step are then used as few-shot examples to generate more similar cases. Each zero-shot test case might be selected in few-shot examples with a probability $\\\\propto \\\\exp(r(\\\\mathbf{x}, \\\\mathbf{y}) / \\\\tau)$\\nSupervised learning: The red team model can be fine-tuned on failing, zero-shot test cases. The training only runs lightly for one epoch to avoid overfitting and preserve sample diversity.', metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}),\n",
       "  Document(page_content=\"Zero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i'll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\", metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}),\n",
       "  Document(page_content='Sign up\\nSign in\\nSign up\\nSign in\\nUnderstanding Prompting, Prompt Engineering and In-Context Learning in LLMs\\nHarish R\\nFollow\\nCodeX\\n--\\nListen\\nShare\\nIntroduction to Prompt Engineering\\nPrompt engineering is a critical aspect of working with language models (LMs), such as GPT (Generative Pre-trained Transformer). Remember, the key to success lies in the careful design of prompts and the strategic use of examples within the context window.\\n--\\n--\\nWritten by Harish R\\nCodeX\\nTechinical Tead by profession and Blogger by vocation — Positive Living, Personal Finance, Money, Entrepreneurship and Life Advice.\\n Help\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams The Role of In-Context Learning\\nIn-context learning is a powerful technique where examples or additional data are included within the prompt to help the model understand and perform the task better. You can approach this task using different strategies:\\nEffectiveness Across Model Sizes\\nLimitations and Fine-Tuning\\nWhile in-context learning is powerful, it’s important to remember the context window limitation.\\nSpecifically, you learned:\\nMaximize Your Productivity with ChatGPT!\\n...by leveraging the power of advanced AI from ChatGPT, Google Bard, and many other tools online\\nDiscover how in my new Ebook:\\nMaximizing Productivity with ChatGPT\\nIt provides great tips with examples of all kinds to make you the boss of AI robots\\nfor brainstorming, editing, expert helper, translator,\\nand much more...\\n It is easier to demonstrate this with the following example:\\nStill using the Vicuna-7B model in GPT4All, but this time, we are providing the prompt:\\nHere you can see that no instruction on what to do is provided, but with some examples, the model can figure out how to respond. LinkedIn |\\nTwitter |\\nFacebook |\\nNewsletter |\\nRSS\\nPrivacy |\\nDisclaimer |\\nTerms |\\nContact |\\nSitemap |\\nSearch Navigation\\nMain Menu\\nWhat Are Zero-Shot Prompting and Few-Shot Prompting\\nIn the literature on language models, you will often encounter the terms “zero-shot prompting” and “few-shot prompting.” The model obviously can understand “awesome” is a positive sensation, but knowing to identify the sensation is because of the instruction at the beginning, “Classify the text into positive, neutral or negative.”\\n\\nThe zero-shot prompt directly instructs the model to perform a task without any additional examples to steer it. We tried a few zero-shot examples in the previous section. Here is one of the examples (ie., text classification) we used: Prompt: Classify the text into neutral, negative or positive. Text: I think the vacation is okay.\\nIt is also the purview of the prompt engineer to understand how to get the best results out of the variety of generative AI models on the market. Tech-led disruptions are accelerating, driven by generative AI\\nBook a live demo of IBM® watsonx.ai\\nGenerative AI models are built on transformer architectures, which enable them to grasp the intricacies of language and process vast amounts of data through neural networks. For example, researchers developed a new AI system that can translate language without being trained on a parallel text; engineers are embedding generative AI in games to engage human players in truly responsive storytelling and even to gain accurate new insights into the astronomical phenomena of black holes. Generative AI relies on the iterative refinement of different prompt engineering techniques to effectively learn from diverse input data and adapt to minimize biases, confusion and produce more accurate responses.\\n Prompt engineering helps generative AI models better comprehend and respond to a wide range of queries, from the simple to the highly technical.\\n\\nSign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nPrompt Engineering 101: Zero, One, and Few-Shot Prompting\\nAn introduction to a basic prompt engineering strategy\\nAashish Nair\\nFollow\\nTowards Data Science\\n--\\nShare\\nIntroduction\\nDespite their seemingly supernatural capabilities, LLMs are ultimately predictive models that simply predict the next word in the sequence of words based on the provided context.\\n Help\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Zero-shot prompting entails relying solely on an LLM’s pre-trained information…\\n--\\n--\\nWritten by Aashish Nair\\nTowards Data Science\\nData Scientist aspiring to teach and learn through writing. As such, their performances don’t just hinge on the vast volumes of data they are trained with; they also depend heavily on the context provided through the users’ inputs.\\n This is often carried out with 3 different methods: zero-shot prompting, one-shot prompting, and few-shot prompting.\\n')]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18f90522020f3b32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
